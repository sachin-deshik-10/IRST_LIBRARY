{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c133d20a",
   "metadata": {},
   "source": [
    "# Advanced Research Features Tutorial\n",
    "\n",
    "This notebook demonstrates the cutting-edge research capabilities in IRST Library, including:\n",
    "- Quantum-inspired neural networks\n",
    "- Physics-informed neural networks\n",
    "- Continual learning methods\n",
    "- Adversarial robustness\n",
    "- Synthetic data generation\n",
    "\n",
    "These features represent the state-of-the-art in infrared small target detection research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import IRST Library research modules\n",
    "from irst_library.research import (\n",
    "    # Quantum Neural Networks\n",
    "    create_quantum_irst_model,\n",
    "    QuantumInspiredLoss,\n",
    "    \n",
    "    # Physics-Informed Networks\n",
    "    create_physics_informed_model,\n",
    "    PhysicsInformedLoss,\n",
    "    \n",
    "    # Continual Learning\n",
    "    create_continual_learning_setup,\n",
    "    ContinualLearningTrainer,\n",
    "    \n",
    "    # Adversarial Robustness\n",
    "    create_attack_suite,\n",
    "    RobustnessEvaluator,\n",
    "    \n",
    "    # Synthetic Data\n",
    "    create_synthetic_dataset,\n",
    "    SyntheticDataConfig\n",
    ")\n",
    "\n",
    "print(\"üöÄ Advanced IRST Library Research Features Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508a658",
   "metadata": {},
   "source": [
    "## 1. Quantum-Inspired Neural Networks\n",
    "\n",
    "Explore quantum computing principles applied to infrared target detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f747d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quantum-inspired hybrid model\n",
    "quantum_model = create_quantum_irst_model(\n",
    "    model_type='hybrid',\n",
    "    input_channels=1,\n",
    "    num_classes=2,\n",
    "    classical_features=256,\n",
    "    quantum_qubits=8\n",
    ")\n",
    "\n",
    "print(f\"‚ú® Quantum Model Architecture:\")\n",
    "print(quantum_model)\n",
    "\n",
    "# Create quantum-inspired loss function\n",
    "quantum_loss = QuantumInspiredLoss(alpha=0.7, beta=0.3)\n",
    "\n",
    "# Test forward pass\n",
    "dummy_input = torch.randn(4, 1, 64, 64)\n",
    "dummy_targets = torch.randint(0, 2, (4,))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = quantum_model(dummy_input)\n",
    "    loss_dict = quantum_loss(\n",
    "        outputs['logits'], \n",
    "        dummy_targets, \n",
    "        outputs['quantum_output']\n",
    "    )\n",
    "\n",
    "print(f\"\\nüîÆ Quantum Model Output Keys: {list(outputs.keys())}\")\n",
    "print(f\"üîÆ Quantum Loss Components: {list(loss_dict.keys())}\")\n",
    "print(f\"üîÆ Total Loss: {loss_dict['total_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8dfaf6",
   "metadata": {},
   "source": [
    "## 2. Physics-Informed Neural Networks\n",
    "\n",
    "Integrate physical laws and constraints into neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create physics-informed model\n",
    "physics_model = create_physics_informed_model(\n",
    "    model_type='standard',\n",
    "    input_channels=1,\n",
    "    num_classes=2,\n",
    "    physics_laws=['atmospheric', 'heat_transfer', 'infrared'],\n",
    "    predict_physics=True\n",
    ")\n",
    "\n",
    "print(f\"üå°Ô∏è Physics-Informed Model:\")\n",
    "print(f\"Number of physics laws: {len(physics_model.physics_laws)}\")\n",
    "\n",
    "# Create physics-informed loss\n",
    "physics_loss_fn = PhysicsInformedLoss(\n",
    "    physics_loss_weight=0.2,\n",
    "    adaptive_weighting=True\n",
    ")\n",
    "\n",
    "# Test physics predictions\n",
    "dummy_coords = torch.rand(4, 2)  # x, y coordinates\n",
    "\n",
    "with torch.no_grad():\n",
    "    physics_outputs = physics_model(dummy_input, coordinates=dummy_coords)\n",
    "    physics_losses = physics_model.compute_physics_loss(\n",
    "        dummy_input, physics_outputs, coordinates=dummy_coords\n",
    "    )\n",
    "    \n",
    "    total_loss = physics_loss_fn(\n",
    "        physics_outputs, dummy_targets, physics_losses\n",
    "    )\n",
    "\n",
    "print(f\"\\nüå°Ô∏è Physics Output Keys: {list(physics_outputs.keys())}\")\n",
    "print(f\"üå°Ô∏è Physics Loss Keys: {list(physics_losses.keys())}\")\n",
    "print(f\"üå°Ô∏è Temperature Range: {physics_outputs['temperature'].min():.1f}K - {physics_outputs['temperature'].max():.1f}K\")\n",
    "print(f\"üå°Ô∏è Total Physics Loss: {total_loss['total_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e79edd",
   "metadata": {},
   "source": [
    "## 3. Continual Learning\n",
    "\n",
    "Learn new tasks without forgetting previous knowledge using Elastic Weight Consolidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503630e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model for continual learning\n",
    "base_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d((4, 4)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 4 * 4, 2)\n",
    ")\n",
    "\n",
    "# Setup continual learning with EWC\n",
    "continual_strategy, replay_buffer = create_continual_learning_setup(\n",
    "    base_model=base_model,\n",
    "    strategy='ewc',\n",
    "    strategy_params={\n",
    "        'lambda_ewc': 1000.0,\n",
    "        'fisher_estimation_samples': 100\n",
    "    },\n",
    "    use_replay=True,\n",
    "    replay_params={\n",
    "        'buffer_size': 1000,\n",
    "        'selection_strategy': 'gradient_episodic'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create continual learning trainer\n",
    "continual_trainer = ContinualLearningTrainer(\n",
    "    model=base_model,\n",
    "    continual_strategy=continual_strategy,\n",
    "    replay_buffer=replay_buffer\n",
    ")\n",
    "\n",
    "print(f\"üß† Continual Learning Setup:\")\n",
    "print(f\"Strategy: {continual_strategy.__class__.__name__}\")\n",
    "print(f\"Replay Buffer Size: {replay_buffer.buffer_size}\")\n",
    "print(f\"Selection Strategy: {replay_buffer.selection_strategy}\")\n",
    "\n",
    "# Simulate adding samples to replay buffer\n",
    "replay_buffer.add_samples(\n",
    "    dummy_input, dummy_targets, task_id=0, model=base_model\n",
    ")\n",
    "\n",
    "print(f\"\\nüß† Replay Buffer Status:\")\n",
    "print(f\"Current size: {replay_buffer.current_size}\")\n",
    "print(f\"Samples added successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bc629",
   "metadata": {},
   "source": [
    "## 4. Adversarial Robustness\n",
    "\n",
    "Evaluate and improve model robustness against adversarial attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f265cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adversarial attack suite\n",
    "attack_suite = create_attack_suite(\n",
    "    epsilon=0.1,\n",
    "    norm='inf',\n",
    "    include_attacks=['fgsm', 'pgd']\n",
    ")\n",
    "\n",
    "print(f\"üõ°Ô∏è Attack Suite Created:\")\n",
    "for i, attack in enumerate(attack_suite):\n",
    "    print(f\"  {i+1}. {attack.__class__.__name__}\")\n",
    "\n",
    "# Create robustness evaluator\n",
    "robustness_evaluator = RobustnessEvaluator(\n",
    "    attacks=attack_suite,\n",
    "    certification_methods=['randomized_smoothing']\n",
    ")\n",
    "\n",
    "# Test single attack\n",
    "test_model = base_model\n",
    "test_model.eval()\n",
    "\n",
    "# Generate adversarial examples with FGSM\n",
    "fgsm_attack = attack_suite[0]  # First attack is FGSM\n",
    "adv_examples = fgsm_attack.generate(test_model, dummy_input, dummy_targets)\n",
    "\n",
    "# Compare clean vs adversarial predictions\n",
    "with torch.no_grad():\n",
    "    clean_outputs = test_model(dummy_input)\n",
    "    adv_outputs = test_model(adv_examples)\n",
    "    \n",
    "    clean_preds = clean_outputs.argmax(dim=1)\n",
    "    adv_preds = adv_outputs.argmax(dim=1)\n",
    "    \n",
    "    attack_success = (clean_preds != adv_preds).float().mean()\n",
    "\n",
    "print(f\"\\nüõ°Ô∏è Attack Results:\")\n",
    "print(f\"Clean predictions: {clean_preds.tolist()}\")\n",
    "print(f\"Adversarial predictions: {adv_preds.tolist()}\")\n",
    "print(f\"Attack success rate: {attack_success:.2%}\")\n",
    "\n",
    "# Compute perturbation statistics\n",
    "perturbation = adv_examples - dummy_input\n",
    "max_perturbation = perturbation.abs().max().item()\n",
    "avg_perturbation = perturbation.abs().mean().item()\n",
    "\n",
    "print(f\"Max perturbation: {max_perturbation:.4f}\")\n",
    "print(f\"Average perturbation: {avg_perturbation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62872f9c",
   "metadata": {},
   "source": [
    "## 5. Synthetic Data Generation\n",
    "\n",
    "Generate realistic synthetic infrared data using physics-based rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure synthetic data generation\n",
    "synthetic_config = SyntheticDataConfig(\n",
    "    image_size=(128, 128),\n",
    "    num_targets=(1, 2),\n",
    "    target_size_range=(5, 12),\n",
    "    temperature_range=(350.0, 450.0),\n",
    "    background_temp=(280.0, 320.0),\n",
    "    noise_level=0.03,\n",
    "    atmospheric_effects=True,\n",
    "    domain_randomization=True\n",
    ")\n",
    "\n",
    "print(f\"üé® Synthetic Data Configuration:\")\n",
    "print(f\"Image size: {synthetic_config.image_size}\")\n",
    "print(f\"Target count: {synthetic_config.num_targets}\")\n",
    "print(f\"Target size range: {synthetic_config.target_size_range}\")\n",
    "print(f\"Temperature range: {synthetic_config.temperature_range}K\")\n",
    "\n",
    "# Create synthetic dataset\n",
    "synthetic_dataset = create_synthetic_dataset(\n",
    "    config=synthetic_config,\n",
    "    dataset_size=100,  # Small for demo\n",
    "    use_gan=False  # Use physics-based rendering\n",
    ")\n",
    "\n",
    "print(f\"\\nüé® Synthetic Dataset Created:\")\n",
    "print(f\"Dataset size: {len(synthetic_dataset)}\")\n",
    "\n",
    "# Generate a few samples\n",
    "sample_data = []\n",
    "for i in range(3):\n",
    "    sample = synthetic_dataset[i]\n",
    "    sample_data.append(sample)\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Image shape: {sample['image'].shape}\")\n",
    "    print(f\"  Has target: {sample['classification_target'].item()}\")\n",
    "    print(f\"  Num targets: {len(sample['metadata'])}\")\n",
    "    \n",
    "    if sample['metadata']:\n",
    "        target_info = sample['metadata'][0]\n",
    "        print(f\"  Target temp: {target_info['temperature']:.1f}K\")\n",
    "        print(f\"  Target size: {target_info['size']} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f89e751",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "\n",
    "Visualize the generated synthetic data and model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f84065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize synthetic samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "fig.suptitle('üé® Synthetic Infrared Data Samples', fontsize=16)\n",
    "\n",
    "for i, sample in enumerate(sample_data[:3]):\n",
    "    image = sample['image'].squeeze().numpy()\n",
    "    mask = sample['mask'].squeeze().numpy()\n",
    "    \n",
    "    # Plot image\n",
    "    axes[0, i].imshow(image, cmap='hot', vmin=0, vmax=1)\n",
    "    axes[0, i].set_title(f'Sample {i+1} - IR Image')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot mask\n",
    "    axes[1, i].imshow(mask, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, i].set_title(f'Sample {i+1} - Target Mask')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Add target information\n",
    "    if sample['metadata']:\n",
    "        target = sample['metadata'][0]\n",
    "        axes[0, i].plot(target['x'], target['y'], 'r+', markersize=10, markeredgewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6eb45a",
   "metadata": {},
   "source": [
    "## 7. Integration Example\n",
    "\n",
    "Demonstrate how these advanced features can be combined for a complete research workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Advanced Research Integration Example\")\n",
    "print(\"======================================\\n\")\n",
    "\n",
    "# Step 1: Generate synthetic training data\n",
    "print(\"Step 1: Generating synthetic training data...\")\n",
    "synthetic_loader = DataLoader(synthetic_dataset, batch_size=8, shuffle=True)\n",
    "print(f\"‚úì Created DataLoader with {len(synthetic_dataset)} samples\\n\")\n",
    "\n",
    "# Step 2: Create physics-informed model\n",
    "print(\"Step 2: Creating physics-informed model...\")\n",
    "research_model = create_physics_informed_model(\n",
    "    input_channels=1,\n",
    "    num_classes=2,\n",
    "    physics_laws=['atmospheric', 'infrared']\n",
    ")\n",
    "print(f\"‚úì Physics-informed model created with {len(research_model.physics_laws)} physics laws\\n\")\n",
    "\n",
    "# Step 3: Setup adversarial training\n",
    "print(\"Step 3: Setting up adversarial training...\")\n",
    "from irst_library.research import create_robust_trainer\n",
    "robust_trainer = create_robust_trainer(\n",
    "    attack_epsilon=0.05,\n",
    "    training_method='trades'\n",
    ")\n",
    "print(f\"‚úì Adversarial trainer configured with TRADES method\\n\")\n",
    "\n",
    "# Step 4: Demonstrate one training step\n",
    "print(\"Step 4: Demonstrating integrated training step...\")\n",
    "sample_batch = next(iter(synthetic_loader))\n",
    "images = sample_batch['image']\n",
    "targets = sample_batch['classification_target']\n",
    "\n",
    "# Physics-informed forward pass\n",
    "physics_outputs = research_model(images)\n",
    "physics_losses = research_model.compute_physics_loss(images, physics_outputs)\n",
    "\n",
    "# Adversarial training loss\n",
    "adv_losses = robust_trainer.compute_adversarial_loss(\n",
    "    research_model, images, targets, physics_outputs['logits']\n",
    ")\n",
    "\n",
    "print(f\"‚úì Physics loss: {physics_losses['total_physics_loss']:.4f}\")\n",
    "print(f\"‚úì Adversarial loss: {adv_losses['total_loss']:.4f}\")\n",
    "print(f\"‚úì Combined advanced training step completed!\\n\")\n",
    "\n",
    "# Step 5: Robustness evaluation\n",
    "print(\"Step 5: Quick robustness evaluation...\")\n",
    "fgsm_adv = attack_suite[0].generate(research_model, images[:4], targets[:4])\n",
    "with torch.no_grad():\n",
    "    clean_acc = (research_model(images[:4])['logits'].argmax(1) == targets[:4]).float().mean()\n",
    "    adv_acc = (research_model(fgsm_adv)['logits'].argmax(1) == targets[:4]).float().mean()\n",
    "\n",
    "print(f\"‚úì Clean accuracy: {clean_acc:.2%}\")\n",
    "print(f\"‚úì Adversarial accuracy: {adv_acc:.2%}\")\n",
    "print(f\"‚úì Robustness gap: {(clean_acc - adv_acc):.2%}\\n\")\n",
    "\n",
    "print(\"üéâ Advanced Research Integration Complete!\")\n",
    "print(\"\\nThis demonstrates how quantum-inspired networks, physics-informed\")\n",
    "print(\"models, continual learning, adversarial robustness, and synthetic\")\n",
    "print(\"data generation can be seamlessly integrated for cutting-edge\")\n",
    "print(\"infrared small target detection research.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d62cb0",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This tutorial covered the advanced research features in IRST Library. To dive deeper:\n",
    "\n",
    "1. **Quantum Neural Networks**: Explore different quantum architectures and compare with classical models\n",
    "2. **Physics-Informed Networks**: Implement custom physics laws for specific applications\n",
    "3. **Continual Learning**: Test on sequential task scenarios with real datasets\n",
    "4. **Adversarial Robustness**: Evaluate certified defenses and adaptive attacks\n",
    "5. **Synthetic Data**: Scale up generation for large-scale training\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Advanced Features Documentation](../docs/ADVANCED_FEATURES.md)\n",
    "- [Research Papers Bibliography](../docs/REFERENCES.md)\n",
    "- [Contributing Guidelines](../CONTRIBUTING.md)\n",
    "- [Community Discussions](https://github.com/your-repo/discussions)\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Ready to push the boundaries of infrared target detection research!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
