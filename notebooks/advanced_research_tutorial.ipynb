{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c133d20a",
   "metadata": {},
   "source": [
    "# Advanced Research Features Tutorial\n",
    "\n",
    "This notebook demonstrates the cutting-edge research capabilities in IRST Library, including:\n",
    "- Quantum-inspired neural networks\n",
    "- Physics-informed neural networks\n",
    "- Continual learning methods\n",
    "- Adversarial robustness\n",
    "- Synthetic data generation\n",
    "\n",
    "These features represent the state-of-the-art in infrared small target detection research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import IRST Library research modules\n",
    "from irst_library.research import (\n",
    "    # Quantum Neural Networks\n",
    "    create_quantum_irst_model,\n",
    "    QuantumInspiredLoss,\n",
    "    \n",
    "    # Physics-Informed Networks\n",
    "    create_physics_informed_model,\n",
    "    PhysicsInformedLoss,\n",
    "    \n",
    "    # Continual Learning\n",
    "    create_continual_learning_setup,\n",
    "    ContinualLearningTrainer,\n",
    "    \n",
    "    # Adversarial Robustness\n",
    "    create_attack_suite,\n",
    "    RobustnessEvaluator,\n",
    "    \n",
    "    # Synthetic Data\n",
    "    create_synthetic_dataset,\n",
    "    SyntheticDataConfig\n",
    ")\n",
    "\n",
    "print(\"üöÄ Advanced IRST Library Research Features Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508a658",
   "metadata": {},
   "source": [
    "## 1. Quantum-Inspired Neural Networks\n",
    "\n",
    "Explore quantum computing principles applied to infrared target detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f747d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quantum-inspired hybrid model\n",
    "quantum_model = create_quantum_irst_model(\n",
    "    model_type='hybrid',\n",
    "    input_channels=1,\n",
    "    num_classes=2,\n",
    "    classical_features=256,\n",
    "    quantum_qubits=8\n",
    ")\n",
    "\n",
    "print(f\"‚ú® Quantum Model Architecture:\")\n",
    "print(quantum_model)\n",
    "\n",
    "# Create quantum-inspired loss function\n",
    "quantum_loss = QuantumInspiredLoss(alpha=0.7, beta=0.3)\n",
    "\n",
    "# Test forward pass\n",
    "dummy_input = torch.randn(4, 1, 64, 64)\n",
    "dummy_targets = torch.randint(0, 2, (4,))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = quantum_model(dummy_input)\n",
    "    loss_dict = quantum_loss(\n",
    "        outputs['logits'], \n",
    "        dummy_targets, \n",
    "        outputs['quantum_output']\n",
    "    )\n",
    "\n",
    "print(f\"\\nüîÆ Quantum Model Output Keys: {list(outputs.keys())}\")\n",
    "print(f\"üîÆ Quantum Loss Components: {list(loss_dict.keys())}\")\n",
    "print(f\"üîÆ Total Loss: {loss_dict['total_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8dfaf6",
   "metadata": {},
   "source": [
    "## 2. Physics-Informed Neural Networks\n",
    "\n",
    "Integrate physical laws and constraints into neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create physics-informed model\n",
    "physics_model = create_physics_informed_model(\n",
    "    model_type='standard',\n",
    "    input_channels=1,\n",
    "    num_classes=2,\n",
    "    physics_laws=['atmospheric', 'heat_transfer', 'infrared'],\n",
    "    predict_physics=True\n",
    ")\n",
    "\n",
    "print(f\"üå°Ô∏è Physics-Informed Model:\")\n",
    "print(f\"Number of physics laws: {len(physics_model.physics_laws)}\")\n",
    "\n",
    "# Create physics-informed loss\n",
    "physics_loss_fn = PhysicsInformedLoss(\n",
    "    physics_loss_weight=0.2,\n",
    "    adaptive_weighting=True\n",
    ")\n",
    "\n",
    "# Test physics predictions\n",
    "dummy_coords = torch.rand(4, 2)  # x, y coordinates\n",
    "\n",
    "with torch.no_grad():\n",
    "    physics_outputs = physics_model(dummy_input, coordinates=dummy_coords)\n",
    "    physics_losses = physics_model.compute_physics_loss(\n",
    "        dummy_input, physics_outputs, coordinates=dummy_coords\n",
    "    )\n",
    "    \n",
    "    total_loss = physics_loss_fn(\n",
    "        physics_outputs, dummy_targets, physics_losses\n",
    "    )\n",
    "\n",
    "print(f\"\\nüå°Ô∏è Physics Output Keys: {list(physics_outputs.keys())}\")\n",
    "print(f\"üå°Ô∏è Physics Loss Keys: {list(physics_losses.keys())}\")\n",
    "print(f\"üå°Ô∏è Temperature Range: {physics_outputs['temperature'].min():.1f}K - {physics_outputs['temperature'].max():.1f}K\")\n",
    "print(f\"üå°Ô∏è Total Physics Loss: {total_loss['total_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e79edd",
   "metadata": {},
   "source": [
    "## 3. Continual Learning\n",
    "\n",
    "Learn new tasks without forgetting previous knowledge using Elastic Weight Consolidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503630e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base model for continual learning\n",
    "base_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d((4, 4)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 4 * 4, 2)\n",
    ")\n",
    "\n",
    "# Setup continual learning with EWC\n",
    "continual_strategy, replay_buffer = create_continual_learning_setup(\n",
    "    base_model=base_model,\n",
    "    strategy='ewc',\n",
    "    strategy_params={\n",
    "        'lambda_ewc': 1000.0,\n",
    "        'fisher_estimation_samples': 100\n",
    "    },\n",
    "    use_replay=True,\n",
    "    replay_params={\n",
    "        'buffer_size': 1000,\n",
    "        'selection_strategy': 'gradient_episodic'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create continual learning trainer\n",
    "continual_trainer = ContinualLearningTrainer(\n",
    "    model=base_model,\n",
    "    continual_strategy=continual_strategy,\n",
    "    replay_buffer=replay_buffer\n",
    ")\n",
    "\n",
    "print(f\"üß† Continual Learning Setup:\")\n",
    "print(f\"Strategy: {continual_strategy.__class__.__name__}\")\n",
    "print(f\"Replay Buffer Size: {replay_buffer.buffer_size}\")\n",
    "print(f\"Selection Strategy: {replay_buffer.selection_strategy}\")\n",
    "\n",
    "# Simulate adding samples to replay buffer\n",
    "replay_buffer.add_samples(\n",
    "    dummy_input, dummy_targets, task_id=0, model=base_model\n",
    ")\n",
    "\n",
    "print(f\"\\nüß† Replay Buffer Status:\")\n",
    "print(f\"Current size: {replay_buffer.current_size}\")\n",
    "print(f\"Samples added successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bc629",
   "metadata": {},
   "source": [
    "## 4. Adversarial Robustness\n",
    "\n",
    "Evaluate and improve model robustness against adversarial attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f265cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adversarial attack suite\n",
    "attack_suite = create_attack_suite(\n",
    "    epsilon=0.1,\n",
    "    norm='inf',\n",
    "    include_attacks=['fgsm', 'pgd']\n",
    ")\n",
    "\n",
    "print(f\"üõ°Ô∏è Attack Suite Created:\")\n",
    "for i, attack in enumerate(attack_suite):\n",
    "    print(f\"  {i+1}. {attack.__class__.__name__}\")\n",
    "\n",
    "# Create robustness evaluator\n",
    "robustness_evaluator = RobustnessEvaluator(\n",
    "    attacks=attack_suite,\n",
    "    certification_methods=['randomized_smoothing']\n",
    ")\n",
    "\n",
    "# Test single attack\n",
    "test_model = base_model\n",
    "test_model.eval()\n",
    "\n",
    "# Generate adversarial examples with FGSM\n",
    "fgsm_attack = attack_suite[0]  # First attack is FGSM\n",
    "adv_examples = fgsm_attack.generate(test_model, dummy_input, dummy_targets)\n",
    "\n",
    "# Compare clean vs adversarial predictions\n",
    "with torch.no_grad():\n",
    "    clean_outputs = test_model(dummy_input)\n",
    "    adv_outputs = test_model(adv_examples)\n",
    "    \n",
    "    clean_preds = clean_outputs.argmax(dim=1)\n",
    "    adv_preds = adv_outputs.argmax(dim=1)\n",
    "    \n",
    "    attack_success = (clean_preds != adv_preds).float().mean()\n",
    "\n",
    "print(f\"\\nüõ°Ô∏è Attack Results:\")\n",
    "print(f\"Clean predictions: {clean_preds.tolist()}\")\n",
    "print(f\"Adversarial predictions: {adv_preds.tolist()}\")\n",
    "print(f\"Attack success rate: {attack_success:.2%}\")\n",
    "\n",
    "# Compute perturbation statistics\n",
    "perturbation = adv_examples - dummy_input\n",
    "max_perturbation = perturbation.abs().max().item()\n",
    "avg_perturbation = perturbation.abs().mean().item()\n",
    "\n",
    "print(f\"Max perturbation: {max_perturbation:.4f}\")\n",
    "print(f\"Average perturbation: {avg_perturbation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62872f9c",
   "metadata": {},
   "source": [
    "## 5. Synthetic Data Generation\n",
    "\n",
    "Generate realistic synthetic infrared data using physics-based rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure synthetic data generation\n",
    "synthetic_config = SyntheticDataConfig(\n",
    "    image_size=(128, 128),\n",
    "    num_targets=(1, 2),\n",
    "    target_size_range=(5, 12),\n",
    "    temperature_range=(350.0, 450.0),\n",
    "    background_temp=(280.0, 320.0),\n",
    "    noise_level=0.03,\n",
    "    atmospheric_effects=True,\n",
    "    domain_randomization=True\n",
    ")\n",
    "\n",
    "print(f\"üé® Synthetic Data Configuration:\")\n",
    "print(f\"Image size: {synthetic_config.image_size}\")\n",
    "print(f\"Target count: {synthetic_config.num_targets}\")\n",
    "print(f\"Target size range: {synthetic_config.target_size_range}\")\n",
    "print(f\"Temperature range: {synthetic_config.temperature_range}K\")\n",
    "\n",
    "# Create synthetic dataset\n",
    "synthetic_dataset = create_synthetic_dataset(\n",
    "    config=synthetic_config,\n",
    "    dataset_size=100,  # Small for demo\n",
    "    use_gan=False  # Use physics-based rendering\n",
    ")\n",
    "\n",
    "print(f\"\\nüé® Synthetic Dataset Created:\")\n",
    "print(f\"Dataset size: {len(synthetic_dataset)}\")\n",
    "\n",
    "# Generate a few samples\n",
    "sample_data = []\n",
    "for i in range(3):\n",
    "    sample = synthetic_dataset[i]\n",
    "    sample_data.append(sample)\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Image shape: {sample['image'].shape}\")\n",
    "    print(f\"  Has target: {sample['classification_target'].item()}\")\n",
    "    print(f\"  Num targets: {len(sample['metadata'])}\")\n",
    "    \n",
    "    if sample['metadata']:\n",
    "        target_info = sample['metadata'][0]\n",
    "        print(f\"  Target temp: {target_info['temperature']:.1f}K\")\n",
    "        print(f\"  Target size: {target_info['size']} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f89e751",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "\n",
    "Visualize the generated synthetic data and model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f84065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize synthetic samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "fig.suptitle('üé® Synthetic Infrared Data Samples', fontsize=16)\n",
    "\n",
    "for i, sample in enumerate(sample_data[:3]):\n",
    "    image = sample['image'].squeeze().numpy()\n",
    "    mask = sample['mask'].squeeze().numpy()\n",
    "    \n",
    "    # Plot image\n",
    "    axes[0, i].imshow(image, cmap='hot', vmin=0, vmax=1)\n",
    "    axes[0, i].set_title(f'Sample {i+1} - IR Image')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot mask\n",
    "    axes[1, i].imshow(mask, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, i].set_title(f'Sample {i+1} - Target Mask')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Add target information\n",
    "    if sample['metadata']:\n",
    "        target = sample['metadata'][0]\n",
    "        axes[0, i].plot(target['x'], target['y'], 'r+', markersize=10, markeredgewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6eb45a",
   "metadata": {},
   "source": [
    "## 7. Integration Example\n",
    "\n",
    "Demonstrate how these advanced features can be combined for a complete research workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Advanced Research Integration Example\")\n",
    "print(\"======================================\\n\")\n",
    "\n",
    "# Step 1: Generate synthetic training data\n",
    "print(\"Step 1: Generating synthetic training data...\")\n",
    "synthetic_loader = DataLoader(synthetic_dataset, batch_size=8, shuffle=True)\n",
    "print(f\"‚úì Created DataLoader with {len(synthetic_dataset)} samples\\n\")\n",
    "\n",
    "# Step 2: Create physics-informed model\n",
    "print(\"Step 2: Creating physics-informed model...\")\n",
    "research_model = create_physics_informed_model(\n",
    "    input_channels=1,\n",
    "    num_classes=2,\n",
    "    physics_laws=['atmospheric', 'infrared']\n",
    ")\n",
    "print(f\"‚úì Physics-informed model created with {len(research_model.physics_laws)} physics laws\\n\")\n",
    "\n",
    "# Step 3: Setup adversarial training\n",
    "print(\"Step 3: Setting up adversarial training...\")\n",
    "from irst_library.research import create_robust_trainer\n",
    "robust_trainer = create_robust_trainer(\n",
    "    attack_epsilon=0.05,\n",
    "    training_method='trades'\n",
    ")\n",
    "print(f\"‚úì Adversarial trainer configured with TRADES method\\n\")\n",
    "\n",
    "# Step 4: Demonstrate one training step\n",
    "print(\"Step 4: Demonstrating integrated training step...\")\n",
    "sample_batch = next(iter(synthetic_loader))\n",
    "images = sample_batch['image']\n",
    "targets = sample_batch['classification_target']\n",
    "\n",
    "# Physics-informed forward pass\n",
    "physics_outputs = research_model(images)\n",
    "physics_losses = research_model.compute_physics_loss(images, physics_outputs)\n",
    "\n",
    "# Adversarial training loss\n",
    "adv_losses = robust_trainer.compute_adversarial_loss(\n",
    "    research_model, images, targets, physics_outputs['logits']\n",
    ")\n",
    "\n",
    "print(f\"‚úì Physics loss: {physics_losses['total_physics_loss']:.4f}\")\n",
    "print(f\"‚úì Adversarial loss: {adv_losses['total_loss']:.4f}\")\n",
    "print(f\"‚úì Combined advanced training step completed!\\n\")\n",
    "\n",
    "# Step 5: Robustness evaluation\n",
    "print(\"Step 5: Quick robustness evaluation...\")\n",
    "fgsm_adv = attack_suite[0].generate(research_model, images[:4], targets[:4])\n",
    "with torch.no_grad():\n",
    "    clean_acc = (research_model(images[:4])['logits'].argmax(1) == targets[:4]).float().mean()\n",
    "    adv_acc = (research_model(fgsm_adv)['logits'].argmax(1) == targets[:4]).float().mean()\n",
    "\n",
    "print(f\"‚úì Clean accuracy: {clean_acc:.2%}\")\n",
    "print(f\"‚úì Adversarial accuracy: {adv_acc:.2%}\")\n",
    "print(f\"‚úì Robustness gap: {(clean_acc - adv_acc):.2%}\\n\")\n",
    "\n",
    "print(\"üéâ Advanced Research Integration Complete!\")\n",
    "print(\"\\nThis demonstrates how quantum-inspired networks, physics-informed\")\n",
    "print(\"models, continual learning, adversarial robustness, and synthetic\")\n",
    "print(\"data generation can be seamlessly integrated for cutting-edge\")\n",
    "print(\"infrared small target detection research.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d62cb0",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This tutorial covered the advanced research features in IRST Library. To dive deeper:\n",
    "\n",
    "1. **Quantum Neural Networks**: Explore different quantum architectures and compare with classical models\n",
    "2. **Physics-Informed Networks**: Implement custom physics laws for specific applications\n",
    "3. **Continual Learning**: Test on sequential task scenarios with real datasets\n",
    "4. **Adversarial Robustness**: Evaluate certified defenses and adaptive attacks\n",
    "5. **Synthetic Data**: Scale up generation for large-scale training\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Advanced Features Documentation](../docs/ADVANCED_FEATURES.md)\n",
    "- [Research Papers Bibliography](../docs/REFERENCES.md)\n",
    "- [Contributing Guidelines](../CONTRIBUTING.md)\n",
    "- [Community Discussions](https://github.com/your-repo/discussions)\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Ready to push the boundaries of infrared target detection research!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1531c3",
   "metadata": {},
   "source": [
    "## 11. Active Learning for Efficient Data Annotation\n",
    "\n",
    "Demonstrate intelligent sample selection strategies to minimize annotation costs while maximizing model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import active learning modules\n",
    "from irst_library.research import (\n",
    "    ActiveLearner,\n",
    "    ActiveLearningConfig,\n",
    "    SamplingStrategy,\n",
    "    StreamingActiveLearner,\n",
    "    create_active_learning_experiment,\n",
    "    benchmark_active_learning_strategies\n",
    ")\n",
    "\n",
    "# Create active learning configuration\n",
    "al_config = ActiveLearningConfig(\n",
    "    strategy=SamplingStrategy.HYBRID,\n",
    "    batch_size=32,\n",
    "    budget=1000,\n",
    "    diversity_weight=0.3,\n",
    "    committee_size=5\n",
    ")\n",
    "\n",
    "# Initialize active learner\n",
    "learner = ActiveLearner(al_config)\n",
    "\n",
    "# Initialize with sample dataset\n",
    "total_samples = 5000\n",
    "initial_labeled = 100\n",
    "learner.initialize_pool(total_samples, initial_labeled)\n",
    "\n",
    "print(f\"üéØ Active Learning Setup:\")\n",
    "print(f\"  Strategy: {al_config.strategy.value}\")\n",
    "print(f\"  Initial labeled: {len(learner.labeled_indices)}\")\n",
    "print(f\"  Unlabeled pool: {len(learner.unlabeled_indices)}\")\n",
    "print(f\"  Batch size: {al_config.batch_size}\")\n",
    "\n",
    "# Simulate active learning round\n",
    "print(\"\\nüìä Active Learning Metrics:\")\n",
    "print(f\"  Total budget: {al_config.budget}\")\n",
    "print(f\"  Diversity weight: {al_config.diversity_weight}\")\n",
    "print(f\"  Committee size: {al_config.committee_size}\")\n",
    "\n",
    "# Create different sampling strategies for comparison\n",
    "strategies = [\"uncertainty\", \"diversity\", \"hybrid\", \"committee\"]\n",
    "print(f\"\\nüîç Available strategies: {strategies}\")\n",
    "\n",
    "# Example of uncertainty sampling\n",
    "uncertainty_config = ActiveLearningConfig(strategy=SamplingStrategy.UNCERTAINTY)\n",
    "uncertainty_learner = ActiveLearner(uncertainty_config)\n",
    "print(f\"\\nüí° Uncertainty Sampling: Selects samples with highest prediction uncertainty\")\n",
    "\n",
    "# Example of diversity sampling  \n",
    "diversity_config = ActiveLearningConfig(strategy=SamplingStrategy.DIVERSITY)\n",
    "diversity_learner = ActiveLearner(diversity_config)\n",
    "print(f\"üé® Diversity Sampling: Selects diverse samples to improve coverage\")\n",
    "\n",
    "# Example of hybrid approach\n",
    "hybrid_config = ActiveLearningConfig(\n",
    "    strategy=SamplingStrategy.HYBRID,\n",
    "    diversity_weight=0.4  # Balance between uncertainty and diversity\n",
    ")\n",
    "hybrid_learner = ActiveLearner(hybrid_config)\n",
    "print(f\"‚öñÔ∏è Hybrid Sampling: Combines uncertainty and diversity ({hybrid_config.diversity_weight:.1f} diversity weight)\")\n",
    "\n",
    "# Streaming active learning for real-time scenarios\n",
    "streaming_learner = StreamingActiveLearner(al_config)\n",
    "print(f\"\\nüåä Streaming Active Learning: For real-time data processing\")\n",
    "print(f\"  Budget tracking: {streaming_learner.annotation_budget_used}/{al_config.budget}\")\n",
    "\n",
    "print(\"\\n‚úÖ Active Learning modules initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate advanced active learning features\n",
    "\n",
    "# 1. Multi-objective Pareto optimization\n",
    "from irst_library.research import ParetoActiveLearner\n",
    "\n",
    "pareto_config = ActiveLearningConfig(\n",
    "    strategy=SamplingStrategy.PARETO,\n",
    "    pareto_objectives=[\"uncertainty\", \"diversity\"]\n",
    ")\n",
    "pareto_learner = ParetoActiveLearner(pareto_config)\n",
    "\n",
    "print(\"üéØ Pareto Active Learning:\")\n",
    "print(f\"  Objectives: {pareto_config.pareto_objectives}\")\n",
    "print(\"  Finds optimal trade-off between multiple selection criteria\")\n",
    "\n",
    "# 2. Expected model change sampling\n",
    "from irst_library.research import ExpectedModelChangeSampler\n",
    "\n",
    "emc_config = ActiveLearningConfig(\n",
    "    strategy=SamplingStrategy.EXPECTED_CHANGE,\n",
    "    gradient_embedding_dim=512\n",
    ")\n",
    "emc_sampler = ExpectedModelChangeSampler(emc_config)\n",
    "\n",
    "print(f\"\\nüîÑ Expected Model Change:\")\n",
    "print(f\"  Gradient embedding dim: {emc_config.gradient_embedding_dim}\")\n",
    "print(\"  Selects samples that would change the model the most\")\n",
    "\n",
    "# 3. Committee-based sampling with ensemble\n",
    "committee_config = ActiveLearningConfig(\n",
    "    strategy=SamplingStrategy.COMMITTEE,\n",
    "    committee_size=7\n",
    ")\n",
    "\n",
    "print(f\"\\nüë• Committee Sampling:\")\n",
    "print(f\"  Committee size: {committee_config.committee_size}\")\n",
    "print(\"  Uses ensemble disagreement to select informative samples\")\n",
    "\n",
    "# 4. Continual active learning\n",
    "continual_config = ActiveLearningConfig(\n",
    "    strategy=SamplingStrategy.HYBRID,\n",
    "    continual_learning=True,\n",
    "    memory_size=5000\n",
    ")\n",
    "continual_learner = ActiveLearner(continual_config)\n",
    "\n",
    "print(f\"\\nüîÑ Continual Active Learning:\")\n",
    "print(f\"  Memory buffer size: {continual_config.memory_size}\")\n",
    "print(\"  Maintains memory for streaming scenarios\")\n",
    "\n",
    "# 5. Budget-aware selection\n",
    "budget_config = ActiveLearningConfig(\n",
    "    strategy=SamplingStrategy.UNCERTAINTY,\n",
    "    budget=500,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "print(f\"\\nüí∞ Budget-Aware Selection:\")\n",
    "print(f\"  Total budget: {budget_config.budget}\")\n",
    "print(f\"  Batch size: {budget_config.batch_size}\")\n",
    "print(f\"  Max rounds: {budget_config.budget // budget_config.batch_size}\")\n",
    "\n",
    "# Demonstrate selection quality evaluation\n",
    "print(f\"\\nüìä Selection Quality Metrics:\")\n",
    "print(\"  - Average pairwise distance (diversity)\")\n",
    "print(\"  - Minimum pairwise distance (coverage)\")\n",
    "print(\"  - Average uncertainty (informativeness)\")\n",
    "print(\"  - Selection efficiency\")\n",
    "\n",
    "# Performance tracking\n",
    "print(f\"\\nüìà Performance Tracking:\")\n",
    "print(\"  - Learning curves\")\n",
    "print(\"  - Annotation efficiency\")\n",
    "print(\"  - Strategy comparison\")\n",
    "print(\"  - Budget utilization\")\n",
    "\n",
    "print(\"\\n‚úÖ Advanced active learning features demonstrated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3adf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking different active learning strategies\n",
    "print(\"üèÜ Active Learning Strategy Benchmarking\")\n",
    "\n",
    "# Define strategies to compare\n",
    "benchmark_strategies = [\n",
    "    \"uncertainty\",\n",
    "    \"diversity\", \n",
    "    \"hybrid\",\n",
    "    \"committee\",\n",
    "    \"expected_change\"\n",
    "]\n",
    "\n",
    "print(f\"\\nComparing strategies: {benchmark_strategies}\")\n",
    "\n",
    "# Simulate benchmark results (in real usage, this would run actual experiments)\n",
    "print(\"\\nüìä Simulated Benchmark Results:\")\n",
    "for strategy in benchmark_strategies:\n",
    "    print(f\"\\n{strategy.upper()} Strategy:\")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Sample efficiency: {np.random.uniform(0.75, 0.95):.3f}\")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Diversity score: {np.random.uniform(0.6, 0.9):.3f}\")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Uncertainty coverage: {np.random.uniform(0.7, 0.95):.3f}\")\n",
    "    print(f\"  ‚îî‚îÄ‚îÄ Computational cost: {np.random.uniform(0.1, 0.8):.3f}\")\n",
    "\n",
    "# Learning curve visualization setup\n",
    "print(f\"\\nüìà Learning Curve Analysis:\")\n",
    "print(\"  - X-axis: Number of labeled samples\")\n",
    "print(\"  - Y-axis: Model accuracy\")\n",
    "print(\"  - Multiple curves for different strategies\")\n",
    "\n",
    "# Strategy recommendation system\n",
    "print(f\"\\nüéØ Strategy Recommendations:\")\n",
    "print(\"  UNCERTAINTY: Best for quick improvements on easy datasets\")\n",
    "print(\"  DIVERSITY: Best for ensuring broad coverage\")\n",
    "print(\"  HYBRID: Best balance for most scenarios\")\n",
    "print(\"  COMMITTEE: Best when computational resources available\")\n",
    "print(\"  PARETO: Best for multi-objective optimization\")\n",
    "\n",
    "# Real-world deployment considerations\n",
    "print(f\"\\nüåç Deployment Considerations:\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ Annotation budget constraints\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ Real-time vs batch processing\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ Domain shift handling\")\n",
    "print(\"  ‚îú‚îÄ‚îÄ Expert annotator availability\")\n",
    "print(\"  ‚îî‚îÄ‚îÄ Computational resource limits\")\n",
    "\n",
    "# Active learning workflow summary\n",
    "print(f\"\\nüîÑ Complete Active Learning Workflow:\")\n",
    "print(\"  1. Initialize with small labeled set\")\n",
    "print(\"  2. Train initial model\")\n",
    "print(\"  3. Select most informative unlabeled samples\")\n",
    "print(\"  4. Annotate selected samples\")\n",
    "print(\"  5. Retrain model with new data\")\n",
    "print(\"  6. Evaluate performance\")\n",
    "print(\"  7. Repeat until budget exhausted or target reached\")\n",
    "\n",
    "print(\"\\n‚úÖ Active learning benchmarking and analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
