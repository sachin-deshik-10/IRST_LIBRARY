{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815f54ff",
   "metadata": {},
   "source": [
    "# IRST Library - Complete Tutorial\n",
    "## Infrared Small Target Detection with Deep Learning\n",
    "\n",
    "Welcome to the comprehensive tutorial for the IRST Library! This notebook will guide you through the complete workflow of infrared small target detection, from installation to deployment.\n",
    "\n",
    "### What you'll learn:\n",
    "- ğŸ”§ **Setup & Installation** - Get started with IRST Library\n",
    "- ğŸ“Š **Data Loading & Exploration** - Work with SIRST dataset\n",
    "- ğŸ§  **Model Training** - Train state-of-the-art models like SERANKNet\n",
    "- ğŸ“ˆ **Evaluation & Metrics** - Assess model performance\n",
    "- ğŸ¯ **Inference** - Detect targets in new images\n",
    "- ğŸš€ **Deployment** - Export and serve models\n",
    "\n",
    "### Prerequisites:\n",
    "- Python 3.8+\n",
    "- PyTorch 1.12+\n",
    "- CUDA (optional, for GPU acceleration)\n",
    "\n",
    "Let's get started! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825a037",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import all the essential libraries we'll need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966fd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# IRST Library - Main components\n",
    "from irst_library import IRSTDetector\n",
    "from irst_library.datasets import SIRSTDataset, IRSTD1kDataset\n",
    "from irst_library.models import SERANKNet, ACMNet, MSHNet\n",
    "from irst_library.training import IRSTTrainer\n",
    "from irst_library.evaluation import IRSTEvaluator\n",
    "from irst_library.utils import visualize_detection, plot_metrics\n",
    "\n",
    "# Computer vision libraries\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Utilities\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c38716",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data\n",
    "\n",
    "Let's load the SIRST dataset and explore its characteristics. The SIRST dataset contains infrared images with small target annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f86128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data directory\n",
    "DATA_DIR = \"./data/SIRST\"\n",
    "MODEL_DIR = \"./models\"\n",
    "OUTPUT_DIR = \"./outputs\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [DATA_DIR, MODEL_DIR, OUTPUT_DIR]:\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load SIRST dataset\n",
    "print(\"ğŸ“Š Loading SIRST Dataset...\")\n",
    "\n",
    "# Training dataset\n",
    "train_dataset = SIRSTDataset(\n",
    "    root=DATA_DIR,\n",
    "    split=\"train\",\n",
    "    transform=None,  # We'll add transforms later\n",
    "    download=True    # Download if not available\n",
    ")\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = SIRSTDataset(\n",
    "    root=DATA_DIR,\n",
    "    split=\"test\",\n",
    "    transform=None,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dataset loaded successfully!\")\n",
    "print(f\"   ğŸ“ˆ Training samples: {len(train_dataset)}\")\n",
    "print(f\"   ğŸ“Š Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Explore dataset statistics\n",
    "sample_image, sample_mask = train_dataset[0]\n",
    "print(f\"\\nğŸ“ Image dimensions: {sample_image.shape}\")\n",
    "print(f\"ğŸ“ Mask dimensions: {sample_mask.shape}\")\n",
    "print(f\"ğŸ¨ Image dtype: {sample_image.dtype}\")\n",
    "print(f\"ğŸ¨ Mask dtype: {sample_mask.dtype}\")\n",
    "print(f\"ğŸ“Š Image range: [{sample_image.min():.3f}, {sample_image.max():.3f}]\")\n",
    "print(f\"ğŸ“Š Mask range: [{sample_mask.min():.3f}, {sample_mask.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410a8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from the dataset\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('SIRST Dataset Sample Images', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(4):\n",
    "    # Get sample\n",
    "    image, mask = train_dataset[i * 50]  # Sample every 50th image\n",
    "    \n",
    "    # Convert to numpy if tensor\n",
    "    if torch.is_tensor(image):\n",
    "        image = image.numpy()\n",
    "    if torch.is_tensor(mask):\n",
    "        mask = mask.numpy()\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, i].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Image {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Ground truth mask\n",
    "    axes[1, i].imshow(mask.squeeze(), cmap='hot')\n",
    "    axes[1, i].set_title(f'Ground Truth {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze target characteristics\n",
    "print(\"\\nğŸ¯ Target Analysis:\")\n",
    "target_counts = []\n",
    "target_sizes = []\n",
    "\n",
    "for i in range(min(100, len(train_dataset))):  # Analyze first 100 samples\n",
    "    _, mask = train_dataset[i]\n",
    "    if torch.is_tensor(mask):\n",
    "        mask = mask.numpy()\n",
    "    \n",
    "    # Count targets\n",
    "    num_targets = len(np.unique(mask)) - 1  # Subtract background\n",
    "    target_counts.append(num_targets)\n",
    "    \n",
    "    # Calculate target sizes\n",
    "    if num_targets > 0:\n",
    "        target_pixels = np.sum(mask > 0)\n",
    "        target_sizes.append(target_pixels)\n",
    "\n",
    "print(f\"ğŸ“Š Average targets per image: {np.mean(target_counts):.2f}\")\n",
    "print(f\"ğŸ“Š Max targets per image: {np.max(target_counts)}\")\n",
    "print(f\"ğŸ“Š Images with targets: {np.sum(np.array(target_counts) > 0)} / {len(target_counts)}\")\n",
    "if target_sizes:\n",
    "    print(f\"ğŸ“Š Average target size: {np.mean(target_sizes):.2f} pixels\")\n",
    "    print(f\"ğŸ“Š Target size range: [{np.min(target_sizes)}, {np.max(target_sizes)}] pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b6842",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Now let's set up data preprocessing pipelines including normalization, augmentation, and proper data loaders for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation pipelines\n",
    "train_transform = A.Compose([\n",
    "    # Geometric transformations\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Flip(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.1,\n",
    "        scale_limit=0.1,\n",
    "        rotate_limit=15,\n",
    "        p=0.5\n",
    "    ),\n",
    "    \n",
    "    # Photometric transformations\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=0.2,\n",
    "        contrast_limit=0.2,\n",
    "        p=0.5\n",
    "    ),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "    \n",
    "    # Normalization\n",
    "    A.Normalize(\n",
    "        mean=[0.485],  # Single channel for infrared\n",
    "        std=[0.229],\n",
    "        max_pixel_value=255.0\n",
    "    ),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize(\n",
    "        mean=[0.485],\n",
    "        std=[0.229],\n",
    "        max_pixel_value=255.0\n",
    "    ),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "# Create datasets with transforms\n",
    "train_dataset_aug = SIRSTDataset(\n",
    "    root=DATA_DIR,\n",
    "    split=\"train\",\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset_clean = SIRSTDataset(\n",
    "    root=DATA_DIR,\n",
    "    split=\"test\",\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "print(f\"âœ… Preprocessing setup complete!\")\n",
    "print(f\"   ğŸ”„ Training dataset with augmentation: {len(train_dataset_aug)} samples\")\n",
    "print(f\"   ğŸ” Test dataset (clean): {len(test_dataset_clean)} samples\")\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset_aug,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset_clean,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"   ğŸ“¦ Train batches: {len(train_loader)}\")\n",
    "print(f\"   ğŸ“¦ Test batches: {len(test_loader)}\")\n",
    "print(f\"   ğŸ”¢ Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Visualize augmented samples\n",
    "print(\"\\nğŸ¨ Augmentation Examples:\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "images, masks = sample_batch\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Data Augmentation Examples', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(4):\n",
    "    # Denormalize for visualization\n",
    "    img = images[i].squeeze().numpy()\n",
    "    img = img * 0.229 + 0.485  # Reverse normalization\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    mask = masks[i].squeeze().numpy()\n",
    "    \n",
    "    axes[0, i].imshow(img, cmap='gray')\n",
    "    axes[0, i].set_title(f'Augmented Image {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(mask, cmap='hot')\n",
    "    axes[1, i].set_title(f'Augmented Mask {i+1}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73648b8e",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Time to train our SERANKNet model! We'll use the IRST Library's built-in trainer with advanced features like mixed precision, learning rate scheduling, and early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11b791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SERANKNet model\n",
    "print(\"ğŸ§  Initializing SERANKNet model...\")\n",
    "\n",
    "model = SERANKNet(\n",
    "    in_channels=1,  # Grayscale infrared images\n",
    "    num_classes=1,  # Binary segmentation\n",
    "    pretrained=True,\n",
    "    use_attention=True\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"âœ… Model initialized on {device}\")\n",
    "print(f\"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"ğŸ“Š Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Set up training configuration\n",
    "config = {\n",
    "    'model_name': 'serank_sirst_tutorial',\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'scheduler': 'cosine',\n",
    "    'warmup_epochs': 5,\n",
    "    'mixed_precision': True,\n",
    "    'gradient_clipping': 1.0,\n",
    "    'early_stopping_patience': 10,\n",
    "    'save_best_only': True,\n",
    "    'monitor_metric': 'val_iou',\n",
    "    'loss_weights': {\n",
    "        'dice': 0.5,\n",
    "        'focal': 0.3,\n",
    "        'iou': 0.2\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = IRSTTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,  # Using test as validation for demo\n",
    "    config=config,\n",
    "    device=device,\n",
    "    save_dir=MODEL_DIR\n",
    ")\n",
    "\n",
    "print(f\"ğŸš€ Trainer initialized with configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Training loop with progress tracking\n",
    "print(f\"\\nğŸ”¥ Starting training for {config['epochs']} epochs...\")\n",
    "print(f\"ğŸ’¾load checkpoint from: {MODEL_DIR}/{config['model_name']}_best.pth\")\n",
    "\n",
    "# Start training\n",
    "training_history = trainer.train()\n",
    "\n",
    "print(f\"âœ… Training completed!\")\n",
    "print(f\"ğŸ’¾ Best model saved at: {MODEL_DIR}/{config['model_name']}_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361b4a9",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Let's evaluate our trained model using comprehensive metrics and visualizations to understand its performance on infrared small target detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9199bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "best_model_path = f\"{MODEL_DIR}/{config['model_name']}_best.pth\"\n",
    "if os.path.exists(best_model_path):\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    print(f\"âœ… Loaded best model from {best_model_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Best model not found, using current model state\")\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = IRSTEvaluator(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    metrics=['iou', 'dice', 'precision', 'recall', 'f1', 'ber']\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"ğŸ“Š Evaluating model on test set...\")\n",
    "model.eval()\n",
    "test_metrics = evaluator.evaluate(test_loader)\n",
    "\n",
    "print(f\"\\nğŸ¯ Test Results:\")\n",
    "print(f\"   IoU Score: {test_metrics['iou']:.4f}\")\n",
    "print(f\"   Dice Score: {test_metrics['dice']:.4f}\")\n",
    "print(f\"   Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"   Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"   F1 Score: {test_metrics['f1']:.4f}\")\n",
    "print(f\"   BER (Background Error Rate): {test_metrics['ber']:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "if training_history:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Training History', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(training_history['train_loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(training_history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    axes[0, 0].set_title('Loss Curves')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # IoU curves\n",
    "    axes[0, 1].plot(training_history['train_iou'], label='Train IoU', linewidth=2)\n",
    "    axes[0, 1].plot(training_history['val_iou'], label='Validation IoU', linewidth=2)\n",
    "    axes[0, 1].set_title('IoU Curves')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('IoU')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate\n",
    "    axes[1, 0].plot(training_history['learning_rate'], linewidth=2, color='orange')\n",
    "    axes[1, 0].set_title('Learning Rate Schedule')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Metrics summary\n",
    "    metrics_data = {\n",
    "        'Metric': ['IoU', 'Dice', 'Precision', 'Recall', 'F1'],\n",
    "        'Score': [test_metrics['iou'], test_metrics['dice'], \n",
    "                 test_metrics['precision'], test_metrics['recall'], test_metrics['f1']]\n",
    "    }\n",
    "    axes[1, 1].bar(metrics_data['Metric'], metrics_data['Score'], color='skyblue', alpha=0.7)\n",
    "    axes[1, 1].set_title('Test Metrics Summary')\n",
    "    axes[1, 1].set_ylim(0, 1)\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(metrics_data['Score']):\n",
    "        axes[1, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Performance analysis by target size\n",
    "print(\"\\nğŸ” Performance Analysis by Target Size:\")\n",
    "size_analysis = evaluator.analyze_by_target_size(test_loader)\n",
    "for size_range, metrics in size_analysis.items():\n",
    "    print(f\"   {size_range}: IoU={metrics['iou']:.4f}, Count={metrics['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32626f6d",
   "metadata": {},
   "source": [
    "## 6. Model Inference\n",
    "\n",
    "Now let's use our trained model to detect infrared small targets in new images and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe2458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create high-level detector for easy inference\n",
    "detector = IRSTDetector.from_pretrained(\n",
    "    model_path=best_model_path,\n",
    "    config=config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"ğŸ¯ IRST Detector initialized for inference!\")\n",
    "\n",
    "# Inference on test samples\n",
    "print(\"\\nğŸ” Running inference on test samples...\")\n",
    "model.eval()\n",
    "\n",
    "# Select random test samples\n",
    "import random\n",
    "test_indices = random.sample(range(len(test_dataset_clean)), 6)\n",
    "\n",
    "fig, axes = plt.subplots(3, 6, figsize=(20, 12))\n",
    "fig.suptitle('Model Inference Results', fontsize=18, fontweight='bold')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, test_idx in enumerate(test_indices):\n",
    "        # Get test sample\n",
    "        image, gt_mask = test_dataset_clean[test_idx]\n",
    "        \n",
    "        # Add batch dimension\n",
    "        image_batch = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Inference\n",
    "        pred_mask = model(image_batch)\n",
    "        pred_mask = torch.sigmoid(pred_mask)  # Apply sigmoid for binary classification\n",
    "        pred_mask = (pred_mask > 0.5).float()  # Threshold\n",
    "        \n",
    "        # Convert back to numpy\n",
    "        image_np = image.squeeze().numpy()\n",
    "        gt_mask_np = gt_mask.squeeze().numpy()\n",
    "        pred_mask_np = pred_mask.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        image_vis = image_np * 0.229 + 0.485\n",
    "        image_vis = np.clip(image_vis, 0, 1)\n",
    "        \n",
    "        # Plot original image\n",
    "        axes[0, idx].imshow(image_vis, cmap='gray')\n",
    "        axes[0, idx].set_title(f'Input Image {idx+1}')\n",
    "        axes[0, idx].axis('off')\n",
    "        \n",
    "        # Plot ground truth\n",
    "        axes[1, idx].imshow(gt_mask_np, cmap='hot', alpha=0.8)\n",
    "        axes[1, idx].imshow(image_vis, cmap='gray', alpha=0.6)\n",
    "        axes[1, idx].set_title(f'Ground Truth {idx+1}')\n",
    "        axes[1, idx].axis('off')\n",
    "        \n",
    "        # Plot prediction\n",
    "        axes[2, idx].imshow(pred_mask_np, cmap='hot', alpha=0.8)\n",
    "        axes[2, idx].imshow(image_vis, cmap='gray', alpha=0.6)\n",
    "        axes[2, idx].set_title(f'Prediction {idx+1}')\n",
    "        axes[2, idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-sample metrics\n",
    "print(\"\\nğŸ“Š Per-sample Performance:\")\n",
    "sample_metrics = []\n",
    "\n",
    "for idx, test_idx in enumerate(test_indices):\n",
    "    image, gt_mask = test_dataset_clean[test_idx]\n",
    "    image_batch = image.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred_mask = model(image_batch)\n",
    "        pred_mask = torch.sigmoid(pred_mask)\n",
    "        pred_mask = (pred_mask > 0.5).float()\n",
    "    \n",
    "    # Calculate IoU for this sample\n",
    "    pred_np = pred_mask.squeeze().cpu().numpy()\n",
    "    gt_np = gt_mask.squeeze().numpy()\n",
    "    \n",
    "    intersection = np.sum(pred_np * gt_np)\n",
    "    union = np.sum(pred_np) + np.sum(gt_np) - intersection\n",
    "    iou = intersection / (union + 1e-8)\n",
    "    \n",
    "    sample_metrics.append(iou)\n",
    "    print(f\"   Sample {idx+1}: IoU = {iou:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Average IoU on selected samples: {np.mean(sample_metrics):.4f}\")\n",
    "\n",
    "# Inference time benchmarking\n",
    "print(\"\\nâš¡ Performance Benchmarking:\")\n",
    "import time\n",
    "\n",
    "# Warm up\n",
    "for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "        _ = model(image_batch)\n",
    "\n",
    "# Benchmark\n",
    "inference_times = []\n",
    "for _ in range(100):\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        _ = model(image_batch)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    inference_times.append(time.time() - start_time)\n",
    "\n",
    "avg_time = np.mean(inference_times) * 1000  # Convert to ms\n",
    "fps = 1.0 / (np.mean(inference_times))\n",
    "\n",
    "print(f\"   â±ï¸ Average inference time: {avg_time:.2f} ms\")\n",
    "print(f\"   ğŸš€ Throughput: {fps:.1f} FPS\")\n",
    "print(f\"   ğŸ’¾ Model size: {os.path.getsize(best_model_path) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82301c1",
   "metadata": {},
   "source": [
    "## 7. Model Export and Deployment\n",
    "\n",
    "Finally, let's export our trained model for production deployment using ONNX and create a simple REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be451196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to ONNX format\n",
    "print(\"ğŸ“¦ Exporting model to ONNX...\")\n",
    "\n",
    "# Create dummy input for ONNX export\n",
    "dummy_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "onnx_path = f\"{OUTPUT_DIR}/serank_sirst_model.onnx\"\n",
    "\n",
    "try:\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size', 2: 'height', 3: 'width'},\n",
    "            'output': {0: 'batch_size', 2: 'height', 3: 'width'}\n",
    "        }\n",
    "    )\n",
    "    print(f\"âœ… ONNX model exported to: {onnx_path}\")\n",
    "    print(f\"ğŸ“¦ ONNX model size: {os.path.getsize(onnx_path) / 1024 / 1024:.2f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ONNX export failed: {e}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_name': 'SERANKNet',\n",
    "    'dataset': 'SIRST',\n",
    "    'input_size': [1, 1, 256, 256],\n",
    "    'num_classes': 1,\n",
    "    'metrics': test_metrics,\n",
    "    'training_config': config,\n",
    "    'export_date': datetime.now().isoformat(),\n",
    "    'model_version': '1.0.0'\n",
    "}\n",
    "\n",
    "import json\n",
    "metadata_path = f\"{OUTPUT_DIR}/model_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Model metadata saved to: {metadata_path}\")\n",
    "\n",
    "# Create deployment package\n",
    "print(\"\\nğŸš€ Creating deployment package...\")\n",
    "\n",
    "deployment_files = {\n",
    "    'model': best_model_path,\n",
    "    'onnx': onnx_path,\n",
    "    'metadata': metadata_path,\n",
    "    'config': f\"{OUTPUT_DIR}/deployment_config.yaml\"\n",
    "}\n",
    "\n",
    "# Create deployment config\n",
    "deployment_config = {\n",
    "    'model': {\n",
    "        'name': 'serank_sirst',\n",
    "        'version': '1.0.0',\n",
    "        'input_shape': [1, 256, 256],\n",
    "        'preprocessing': {\n",
    "            'normalize': True,\n",
    "            'mean': [0.485],\n",
    "            'std': [0.229]\n",
    "        },\n",
    "        'postprocessing': {\n",
    "            'threshold': 0.5,\n",
    "            'min_target_size': 5\n",
    "        }\n",
    "    },\n",
    "    'api': {\n",
    "        'host': '0.0.0.0',\n",
    "        'port': 8000,\n",
    "        'max_batch_size': 16,\n",
    "        'timeout': 30\n",
    "    },\n",
    "    'monitoring': {\n",
    "        'log_predictions': True,\n",
    "        'collect_metrics': True,\n",
    "        'alert_threshold': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "import yaml\n",
    "with open(deployment_files['config'], 'w') as f:\n",
    "    yaml.dump(deployment_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"âœ… Deployment configuration saved!\")\n",
    "\n",
    "# Simple REST API example\n",
    "print(\"\\nğŸŒ Creating sample REST API...\")\n",
    "\n",
    "api_code = '''\n",
    "from flask import Flask, request, jsonify\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import onnxruntime as ort\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load ONNX model\n",
    "ort_session = ort.InferenceSession(\"serank_sirst_model.onnx\")\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({'status': 'healthy', 'model': 'serank_sirst'})\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Get image from request\n",
    "        data = request.json\n",
    "        image_b64 = data['image']\n",
    "        \n",
    "        # Decode image\n",
    "        image_bytes = base64.b64decode(image_b64)\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert('L')\n",
    "        \n",
    "        # Preprocess\n",
    "        image = image.resize((256, 256))\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        image_array = (image_array - 0.485) / 0.229\n",
    "        image_array = image_array[None, None, :, :]  # Add batch and channel dims\n",
    "        \n",
    "        # Inference\n",
    "        outputs = ort_session.run(None, {'input': image_array})\n",
    "        prediction = outputs[0][0, 0]  # Remove batch and channel dims\n",
    "        \n",
    "        # Postprocess\n",
    "        prediction = 1 / (1 + np.exp(-prediction))  # Sigmoid\n",
    "        binary_mask = (prediction > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Count targets\n",
    "        from scipy import ndimage\n",
    "        labeled, num_targets = ndimage.label(binary_mask)\n",
    "        \n",
    "        return jsonify({\n",
    "            'num_targets': int(num_targets),\n",
    "            'confidence': float(np.max(prediction)),\n",
    "            'prediction_shape': prediction.shape,\n",
    "            'status': 'success'\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e), 'status': 'error'}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=8000, debug=True)\n",
    "'''\n",
    "\n",
    "api_path = f\"{OUTPUT_DIR}/api_server.py\"\n",
    "with open(api_path, 'w') as f:\n",
    "    f.write(api_code)\n",
    "\n",
    "print(f\"âœ… REST API created: {api_path}\")\n",
    "\n",
    "# Docker deployment\n",
    "dockerfile_content = '''\n",
    "FROM python:3.8-slim\n",
    "\n",
    "# Install dependencies\n",
    "RUN pip install torch torchvision flask onnxruntime numpy pillow scipy\n",
    "\n",
    "# Copy model files\n",
    "COPY serank_sirst_model.onnx /app/\n",
    "COPY api_server.py /app/\n",
    "COPY model_metadata.json /app/\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Run API\n",
    "CMD [\"python\", \"api_server.py\"]\n",
    "'''\n",
    "\n",
    "dockerfile_path = f\"{OUTPUT_DIR}/Dockerfile\"\n",
    "with open(dockerfile_path, 'w') as f:\n",
    "    f.write(dockerfile_content)\n",
    "\n",
    "print(f\"âœ… Dockerfile created: {dockerfile_path}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nğŸ‰ Deployment Package Ready!\")\n",
    "print(f\"ğŸ“ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"   ğŸ“¦ PyTorch model: {os.path.basename(best_model_path)}\")\n",
    "print(f\"   ğŸ“¦ ONNX model: {os.path.basename(onnx_path)}\")\n",
    "print(f\"   ğŸ“„ Metadata: model_metadata.json\")\n",
    "print(f\"   âš™ï¸ Config: deployment_config.yaml\")\n",
    "print(f\"   ğŸŒ API: api_server.py\")\n",
    "print(f\"   ğŸ³ Docker: Dockerfile\")\n",
    "\n",
    "print(f\"\\nğŸš€ To deploy:\")\n",
    "print(f\"   1. cd {OUTPUT_DIR}\")\n",
    "print(f\"   2. docker build -t irst-api .\")\n",
    "print(f\"   3. docker run -p 8000:8000 irst-api\")\n",
    "print(f\"   4. Test: curl -X GET http://localhost:8000/health\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Final Model Performance:\")\n",
    "print(f\"   ğŸ¯ IoU: {test_metrics['iou']:.4f}\")\n",
    "print(f\"   âš¡ Speed: {fps:.1f} FPS\")\n",
    "print(f\"   ğŸ’¾ Size: {os.path.getsize(best_model_path) / 1024 / 1024:.2f} MB\")\n",
    "print(f\"\\nâœ¨ Tutorial completed successfully! âœ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630d0d1",
   "metadata": {},
   "source": [
    "## ğŸ¯ What's Next?\n",
    "\n",
    "Congratulations! You've completed the comprehensive IRST Library tutorial. Here are your next steps:\n",
    "\n",
    "### ğŸ“š **Explore More Resources**\n",
    "\n",
    "- **[Model Zoo](../docs/models.md)** - Discover all available pretrained models and their capabilities\n",
    "- **[Dataset Guide](../docs/datasets.md)** - Learn about dataset preparation and advanced data handling\n",
    "- **[Benchmarks](../docs/BENCHMARKS.md)** - Compare performance across different models and datasets\n",
    "- **[API Reference](../docs/api_reference.md)** - Complete API documentation with examples\n",
    "\n",
    "### ğŸ§ª **Advanced Tutorials**\n",
    "\n",
    "Continue your journey with specialized notebooks:\n",
    "\n",
    "1. **[Advanced Training Techniques](training_advanced.ipynb)** - Multi-GPU training, hyperparameter optimization, and custom losses\n",
    "2. **[Model Zoo Exploration](model_zoo_tutorial.ipynb)** - Compare different architectures and find the best model for your use case\n",
    "3. **[Dataset Preparation](dataset_preparation.ipynb)** - Create custom datasets and advanced augmentation strategies\n",
    "4. **[Production Deployment](deployment_tutorial.ipynb)** - Deploy models to cloud platforms and edge devices\n",
    "5. **[Benchmarking & Analysis](benchmarking_tutorial.ipynb)** - Comprehensive performance analysis and optimization\n",
    "\n",
    "### ğŸš€ **Production Ready**\n",
    "\n",
    "Your model is now ready for:\n",
    "- **Research Publications** - Use in academic papers with proper citations\n",
    "- **Commercial Applications** - Deploy in production environments\n",
    "- **Open Source Contributions** - Contribute back to the community\n",
    "- **Custom Implementations** - Extend the library for specific use cases\n",
    "\n",
    "### ğŸ¤ **Community & Support**\n",
    "\n",
    "- **GitHub Issues** - Report bugs or request features\n",
    "- **Discussions** - Ask questions and share experiences\n",
    "- **Contributions** - Help improve the library\n",
    "- **Publications** - Cite our work in your research\n",
    "\n",
    "### ğŸ“Š **Performance Summary**\n",
    "\n",
    "Your trained model achieved:\n",
    "- **IoU Score**: High accuracy infrared target detection\n",
    "- **Inference Speed**: Real-time performance capabilities\n",
    "- **Model Size**: Optimized for deployment\n",
    "- **Export Formats**: PyTorch, ONNX, and deployment-ready packages\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ **Congratulations!**\n",
    "\n",
    "You've successfully:\n",
    "âœ… Loaded and explored the SIRST dataset  \n",
    "âœ… Implemented data preprocessing and augmentation  \n",
    "âœ… Trained a state-of-the-art SERANKNet model  \n",
    "âœ… Evaluated model performance with comprehensive metrics  \n",
    "âœ… Performed inference on new images  \n",
    "âœ… Exported the model for production deployment  \n",
    "âœ… Created a complete deployment package  \n",
    "\n",
    "**Happy target detecting!** ğŸ¯âœ¨"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
